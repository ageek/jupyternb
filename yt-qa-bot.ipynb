{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7924d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d5ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecbe276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6b02bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/home/tom/two/envapi/my-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980a171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings= OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad208627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a db\n",
    "def creating_db(video_url):\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "    \n",
    "    '''\n",
    "    when a user asks a question, this database will be used to perform the similarity search and \n",
    "    generate output based on that \n",
    "    '''\n",
    "    db=Chroma.from_documents(docs, embedding=embeddings)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43230b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2c1b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get response\n",
    "def get_response(db, query, k=5):\n",
    "    '''\n",
    "    gpt-3.5 turbo can handle up to 4097 tokens. Setting the chunksize to 1000 and k to 4 maximizes\n",
    "    the number of tokens to analyze.\n",
    "    '''\n",
    "    \n",
    "    docs = db.similarity_search(query, k)\n",
    "    \n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    \n",
    "    chat = ChatOpenAI(temperature=.4)\n",
    "    \n",
    "    #tempalte\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant who can answer question from Youtube videos based on the video's transcript: {docs}\n",
    "    Only use the factual information from transcript to answer the question.\n",
    "    Do not try to make up an answer if you dont have the corresponding datato answer. \n",
    "    If you feel like you don't have enough information to answer the question, say: \"Sorry, I cannot answer that\".\n",
    "    Your answer should be verbose and detailed.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    \n",
    "    #human question prompt\n",
    "    \n",
    "    human_template='Answer the following question: {question}'\n",
    "    \n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt]\n",
    "    )\n",
    "    \n",
    "    #chaining\n",
    "    \n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt, verbose=True)\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    \n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27382ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=H39Z_720T5s\"\n",
    "query=\"what are encoders?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a62bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = creating_db(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6aed14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x7f408bc7b610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ef4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    }
   ],
   "source": [
    "response, docs = get_response(mydb, query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eb415a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Encoders are an essential component of the transformer architecture. They are responsible for accepting inputs, such as text, and converting them into numerical representations or embeddings. These embeddings capture the meaning and context of the input text.The encoder utilizes the self-attention mechanism as its main component. Self-attention allows the encoder to focus on different parts of the input text and assign varying levels of importance to each word or token. This mechanism helps capture the relationships and dependencies between different words in the input.The encoder also has a bi-directional property, meaning it considers both the left and right context of each word when generating the embeddings. This allows the encoder to capture a comprehensive understanding of the input text.The numerical representations generated by the encoder can also be referred to as features or embeddings. These embeddings are then passed on to the decoder for further processing and prediction.In summary, encoders in the transformer architecture convert input text into numerical representations using the self-attention mechanism. They capture the meaning and context of the text and provide these embeddings to the decoder for generating predictions.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae1a81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='as well. It differs from the encoder due to its\\xa0\\xa0 uni-directional property, and is traditionally\\xa0\\nused in an auto-regressive manner. Here too,\\xa0\\xa0 we recommend you check out the video on decoders\\xa0\\nespecially to understand how all of this works.\\xa0\\xa0 Combining the two parts results in what is known\\xa0\\nas an encoder-decoder, or a sequence-to-sequence\\xa0\\xa0 transformer. The encoder accepts inputs and\\xa0\\ncomputes a high-level representation of those\\xa0\\xa0 inputs. These outputs are then passed to the\\xa0\\ndecoder. The decoder uses the encoder\\'s output\\xa0\\xa0 alongside other inputs, in order to generate\\xa0\\na prediction. It then predicts an output,\\xa0\\xa0 which it will re-use in future iterations,\\xa0\\nhence the term \"auto-regressive\".\\xa0\\xa0 Finally, to get an understanding\\xa0\\nof the encoder-decoders as a whole,\\xa0\\xa0 we recommend you check out\\xa0\\nthe video on encoder-decoders.', metadata={'source': 'H39Z_720T5s'}),\n",
       " Document(page_content=\"into two parts. On the left we have the encoder,\\xa0\\xa0 and on the right, the decoder. These two can\\xa0\\nbe used together, but they can also be used\\xa0\\xa0 independently! Let's understand how these work:\\xa0\\nThe encoder accepts inputs that represent text.\\xa0\\xa0 It converts this text, these words, into numerical\\xa0\\nrepresentations. These numerical representations\\xa0\\xa0 can also be called embeddings, or features. We'll\\xa0\\nsee that it uses the self-attention mechanism as\\xa0\\xa0 its main component. We recommend you check out the\\xa0\\nvideo on encoders especially to understand what is\\xa0\\xa0 this numerical representation, as well as how it\\xa0\\nworks. We'll study the self-attention mechanism as\\xa0\\xa0 well as its bi-directional properties. The decoder\\xa0\\nis similar to the encoder: it can also accept\\xa0\\xa0 the same inputs as the encoder: inputs that\\xa0\\nrepresent text. It uses a similar mechanism as\\xa0\\xa0 the encoder, which is the masked self-attention\\xa0\\nas well. It differs from the encoder due to its\\xa0\\xa0 uni-directional property, and is traditionally\", metadata={'source': 'H39Z_720T5s'}),\n",
       " Document(page_content='Let\\'s study the transformer architecture.\\xa0\\xa0 This video is the introductory video to\\xa0\\nthe encoders, decoders, and encoder-decoder\\xa0\\xa0 series of videos. In this series, we\\'ll try to\\xa0\\nunderstand what makes a Transformer network,\\xa0\\xa0 and we\\'ll try to explain it in simple, high-level\\xa0\\nterms. No understanding of neural networks is\\xa0\\xa0 necessary, only an understanding of\\xa0\\nbasic vectors and tensors may help.\\xa0\\xa0 To get started, we\\'ll take up this diagram\\xa0\\nfrom the original transformer paper,\\xa0\\xa0 entitled \"Attention is all you need\". As we\\'ll\\xa0\\nsee here we can leverage only some parts of it,\\xa0\\xa0 according to what we\\'re trying to do. We won\\'t\\xa0\\ndive into the specific layers building up that\\xa0\\xa0 architecture, but we\\'ll try to understand the\\xa0\\ndifferent ways this architecture can be used.\\xa0\\xa0 Let\\'s first start by splitting that architecture\\xa0\\ninto two parts. On the left we have the encoder,\\xa0\\xa0 and on the right, the decoder. These two can', metadata={'source': 'H39Z_720T5s'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef83d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The encoder in a transformer network accepts textual inputs and converts them into numerical representations called embeddings or features. It utilizes the self-attention mechanism as its main component to capture the relationships between different words in the input. These embeddings are then used to compute a high-level representation of the inputs, which are passed on to the decoder for further processing and prediction.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"how does the encoder work, explain in 3 sentence only?\"\n",
    "response, docs = get_response(mydb, query, k=3)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd724334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"into two parts. On the left we have the encoder,\\xa0\\xa0 and on the right, the decoder. These two can\\xa0\\nbe used together, but they can also be used\\xa0\\xa0 independently! Let's understand how these work:\\xa0\\nThe encoder accepts inputs that represent text.\\xa0\\xa0 It converts this text, these words, into numerical\\xa0\\nrepresentations. These numerical representations\\xa0\\xa0 can also be called embeddings, or features. We'll\\xa0\\nsee that it uses the self-attention mechanism as\\xa0\\xa0 its main component. We recommend you check out the\\xa0\\nvideo on encoders especially to understand what is\\xa0\\xa0 this numerical representation, as well as how it\\xa0\\nworks. We'll study the self-attention mechanism as\\xa0\\xa0 well as its bi-directional properties. The decoder\\xa0\\nis similar to the encoder: it can also accept\\xa0\\xa0 the same inputs as the encoder: inputs that\\xa0\\nrepresent text. It uses a similar mechanism as\\xa0\\xa0 the encoder, which is the masked self-attention\\xa0\\nas well. It differs from the encoder due to its\\xa0\\xa0 uni-directional property, and is traditionally\", metadata={'source': 'H39Z_720T5s'}),\n",
       " Document(page_content='as well. It differs from the encoder due to its\\xa0\\xa0 uni-directional property, and is traditionally\\xa0\\nused in an auto-regressive manner. Here too,\\xa0\\xa0 we recommend you check out the video on decoders\\xa0\\nespecially to understand how all of this works.\\xa0\\xa0 Combining the two parts results in what is known\\xa0\\nas an encoder-decoder, or a sequence-to-sequence\\xa0\\xa0 transformer. The encoder accepts inputs and\\xa0\\ncomputes a high-level representation of those\\xa0\\xa0 inputs. These outputs are then passed to the\\xa0\\ndecoder. The decoder uses the encoder\\'s output\\xa0\\xa0 alongside other inputs, in order to generate\\xa0\\na prediction. It then predicts an output,\\xa0\\xa0 which it will re-use in future iterations,\\xa0\\nhence the term \"auto-regressive\".\\xa0\\xa0 Finally, to get an understanding\\xa0\\nof the encoder-decoders as a whole,\\xa0\\xa0 we recommend you check out\\xa0\\nthe video on encoder-decoders.', metadata={'source': 'H39Z_720T5s'}),\n",
       " Document(page_content='Let\\'s study the transformer architecture.\\xa0\\xa0 This video is the introductory video to\\xa0\\nthe encoders, decoders, and encoder-decoder\\xa0\\xa0 series of videos. In this series, we\\'ll try to\\xa0\\nunderstand what makes a Transformer network,\\xa0\\xa0 and we\\'ll try to explain it in simple, high-level\\xa0\\nterms. No understanding of neural networks is\\xa0\\xa0 necessary, only an understanding of\\xa0\\nbasic vectors and tensors may help.\\xa0\\xa0 To get started, we\\'ll take up this diagram\\xa0\\nfrom the original transformer paper,\\xa0\\xa0 entitled \"Attention is all you need\". As we\\'ll\\xa0\\nsee here we can leverage only some parts of it,\\xa0\\xa0 according to what we\\'re trying to do. We won\\'t\\xa0\\ndive into the specific layers building up that\\xa0\\xa0 architecture, but we\\'ll try to understand the\\xa0\\ndifferent ways this architecture can be used.\\xa0\\xa0 Let\\'s first start by splitting that architecture\\xa0\\ninto two parts. On the left we have the encoder,\\xa0\\xa0 and on the right, the decoder. These two can', metadata={'source': 'H39Z_720T5s'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "374a3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    #query=\"how does the encoder work, explain in 3 sentence only?\"\n",
    "    response, docs = get_response(mydb, query, k=3)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aac2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attention is a mechanism used in the transformer architecture that allows a model to weigh the importance of different words in a sentence when encoding or decoding. It calculates the attention score for each word by considering the relationships between all the words in the input sequence, enabling the model to focus on relevant information and capture long-range dependencies.\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(\"what is self attention, anser in 2 sentence only\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02c9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botvenv",
   "language": "python",
   "name": "botvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
